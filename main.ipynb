{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from data_normalizer import normalize\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(text):\n",
    "    with open('data/intent_alias_data.json', encoding=\"utf8\") as f:\n",
    "        dictionary = json.load(f)\n",
    "    \n",
    "    out = {}\n",
    "    for concept in dictionary:\n",
    "        for alias in sorted(dictionary[concept], key=len, reverse=1):\n",
    "            if alias in text:\n",
    "                out[concept]=alias\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_MODEL_BERT = \"phobert_large\"\n",
    "NER_MODEL_BILSTM = \"BiLSTM\"\n",
    "NER_MODEL_BILSTM_CRF = \"BiLSTM+CRF\"\n",
    "\n",
    "INTENT_MODEL_ONE_VS_REST =\"onevsrest\"\n",
    "\n",
    "def extract_ner(text, model=NER_MODEL_BERT):\n",
    "    \"\"\"\n",
    "    Input Arguments:\n",
    "        - text : the sentence which will be extracted NER\n",
    "    \"\"\"\n",
    "    ner_service_url = os.getenv(\"NER_SERVICE_URL\", default=\"http://localhost:8001/api/v1/ner\")\n",
    "    data = {'model': model, 'text': text}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(ner_service_url, data=json.dumps(data), headers=headers)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_postprocess(entities_raw):\n",
    "    \"\"\"Postprocess for NER: \n",
    "    1. normalize values\n",
    "    2. only accept the related information with previous question\n",
    "\n",
    "    Args:\n",
    "        entities_raw (Dict): result of NER service\n",
    "\n",
    "    Returns:\n",
    "        Dict, Dict: raw and normalized entities\n",
    "    \"\"\"\n",
    "    entities_normed = dict()\n",
    "    entities_raw_out = dict()\n",
    "    for entity in entities_raw:\n",
    "        key = entity['label']\n",
    "        if key == 'O': continue\n",
    "        value_raw = entity['content']\n",
    "        if key not in entities_raw_out.keys():\n",
    "            entities_raw_out[key] = [value_raw]\n",
    "        else:\n",
    "            entities_raw_out[key].append(value_raw)\n",
    "        \n",
    "        value_normed = normalize(value_raw, key)\n",
    "        if key not in entities_normed.keys():\n",
    "            entities_normed[key] = [value_normed]\n",
    "        else:\n",
    "            entities_normed[key].append(value_normed)\n",
    "    \n",
    "    return entities_raw_out, entities_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    entities_raw = extract_ner(text)\n",
    "    _, entities = ner_postprocess(entities_raw)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "def gen_query(targets, evidences):\n",
    "    out = \"\"\"\n",
    "    MATCH ({}) \n",
    "    WHERE {}\n",
    "    RETURN {}\n",
    "    LIMIT 100\n",
    "        \"\"\"\n",
    "    conditions = []\n",
    "\n",
    "    attrs = [constants.LABEL_REAL_ESTATE_TYPE, constants.LABEL_REAL_ESTATE_SUB_TYPE, \\\n",
    "            constants.LABEL_POSITION, constants.LABEL_DIRECTION, \\\n",
    "            constants.LABEL_FRONT_LENGTH, constants.LABEL_ROAD_WIDTH, \\\n",
    "            constants.LABEL_FLOOR, constants.LABEL_BED_ROOM, constants.LABEL_LIVING_ROOM, constants.LABEL_BATH_ROOM, \\\n",
    "            constants.LABEL_SURROUNDING, constants.LABEL_PROJECT_NAME, \\\n",
    "            constants.LABEL_LEGAL, constants.LABEL_TRANSACTION]\n",
    "    key2dbcol = {\n",
    "                'tang': constants.LABEL_FLOOR,\n",
    "                'ban cong': constants.LABEL_FLOOR_BAN_CONG,\n",
    "                'gac': constants.LABEL_FLOOR_GAC,\n",
    "                'ham': constants.LABEL_FLOOR_HAM,\n",
    "                'lung': constants.LABEL_FLOOR_LUNG,\n",
    "                'san thuong': constants.LABEL_FLOOR_SAN_THUONG,\n",
    "                'tret': constants.LABEL_FLOOR_TRET\n",
    "            }\n",
    "\n",
    "    for attr in attrs:\n",
    "        if attr in evidences:\n",
    "            if attr == constants.LABEL_FLOOR:\n",
    "                for val in evidences[attr]:\n",
    "                    target_k = key2dbcol[val['type']]\n",
    "                    target_v = val['value']\n",
    "                    conditions.append(f\"{target_k} = '{target_v}'\")\n",
    "            else:\n",
    "                conditions.append(f\"{attr} = '{evidences[attr][0]}'\")\n",
    "    \n",
    "    loc_attrs = [constants.LABEL_DISTRICT, constants.LABEL_CITY, constants.LABEL_WARD, constants.LABEL_STREET]\n",
    "    for attr in loc_attrs:\n",
    "        if attr in evidences:\n",
    "            conditions.append(f\"{attr}.name = '{evidences[attr][0]}'\")\n",
    "    \n",
    "    PRICE_OFFSET_CONST = 0.1\n",
    "    if constants.LABEL_PRICE in evidences:\n",
    "        for ele in evidences[constants.LABEL_PRICE][:1]:\n",
    "            low, high = ele\n",
    "            if high is None:\n",
    "                high = low + low*PRICE_OFFSET_CONST\n",
    "                low = low - low*PRICE_OFFSET_CONST\n",
    "            \n",
    "            conditions.append(f\"{constants.LABEL_PRICE} BETWEEN {low} AND {high}\")\n",
    "    \n",
    "    AREA_OFFSET_CONST = 0.1\n",
    "    if constants.LABEL_AREA in evidences:\n",
    "        for ele in evidences[constants.LABEL_AREA][:1]:\n",
    "            low, high = ele\n",
    "            if high is None:\n",
    "                high = low + low*AREA_OFFSET_CONST\n",
    "                low = low - low*AREA_OFFSET_CONST\n",
    "            \n",
    "            conditions.append(f\"{constants.LABEL_AREA} BETWEEN {low} AND {high}\")\n",
    "    \n",
    "    if constants.LABEL_USAGE in evidences:\n",
    "        conditions.append(\"({})\".format(\" OR \".join([f\"{constants.LABEL_USAGE} LIKE '%, {x},%' OR {constants.LABEL_USAGE} LIKE '{x}, %' OR {constants.LABEL_USAGE} LIKE '%, {x}'\" for x in evidences[constants.LABEL_USAGE]])))\n",
    "\n",
    "    if not targets:\n",
    "        targets = ['*']\n",
    "\n",
    "    return out.format(\n",
    "        ', '.join(targets),\n",
    "        ' AND '.join([f\"{x}\" for x in conditions]),\n",
    "        ', '.join(targets),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "\n",
    "def gen_query_ontology(text):\n",
    "    table = prettytable.PrettyTable([\"Step\", \"Result\"])\n",
    "    table.add_row([\"Input\", text])\n",
    "    \n",
    "    concepts = get_concepts(text)\n",
    "    evidences = get_entities(text)\n",
    "    \n",
    "    table.add_rows([\n",
    "        [\"Match alias\", concepts],\n",
    "        [\"Find individuals\", evidences]\n",
    "    ])\n",
    "    \n",
    "    targets = list(set(concepts.keys()).difference(set(evidences.keys())))\n",
    "    table.add_row([\"Referents\", targets])\n",
    "\n",
    "    query = gen_query(targets,evidences)\n",
    "    table.add_row([\"Query\", query])\n",
    "    \n",
    "    print(table)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidences:  {'district': ['8']}\n",
      "attr:  district\n",
      "-----\n",
      "+------------------+-------------------------------------------------------------------------------+\n",
      "|       Step       |                                     Result                                    |\n",
      "+------------------+-------------------------------------------------------------------------------+\n",
      "|      Input       |                   nhà ở q8 thường có giá khoảng bao nhiêu ạ                   |\n",
      "|   Match alias    | {'Price': 'giá khoảng bao nhiêu', 'House': 'nhà', 'Yes': 'có', 'Hello': 'hi'} |\n",
      "| Find individuals |                              {'district': ['8']}                              |\n",
      "|    Referents     |                       ['Price', 'Yes', 'House', 'Hello']                      |\n",
      "|      Query       |                                                                               |\n",
      "|                  |                         MATCH (Price, Yes, House, Hello)                      |\n",
      "|                  |                             WHERE district.name = '8'                         |\n",
      "|                  |                          RETURN Price, Yes, House, Hello                      |\n",
      "|                  |                                     LIMIT 100                                 |\n",
      "|                  |                                                                               |\n",
      "+------------------+-------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "text = \"nhà ở q8 thường có giá khoảng bao nhiêu ạ\"\n",
    "# text = \"mình đang có 2 tỷ, nên mua nhà hoặc căn hộ ở quận nào nhỉ\"\n",
    "# text = \"nhà hoặc căn hộ giá khoảng 2 tỷ thì mua ở quận nào nhỉ\"\n",
    "\n",
    "gen_query_ontology(text)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
