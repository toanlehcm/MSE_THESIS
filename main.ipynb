{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ToanLe\\AppData\\Roaming\\Python\\Python37\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from data_normalizer import normalize\n",
    "from dotenv import load_dotenv\n",
    "import constants\n",
    "import prettytable\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(text):\n",
    "    with open('data/intent_alias_data.json', encoding=\"utf8\") as f:\n",
    "        dictionary = json.load(f)\n",
    "\n",
    "    out = {}\n",
    "    for concept in dictionary:\n",
    "        for alias in sorted(dictionary[concept], key=len, reverse=1):\n",
    "            if alias in text:\n",
    "                out[concept] = alias\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_relation(concept_key_list):\n",
    "    with open('data/match_relation_dict.json', encoding=\"utf8\") as f:\n",
    "        match_relation_dict = json.load(f)\n",
    "\n",
    "    match_relation_out = []\n",
    "    for start_node in match_relation_dict:\n",
    "        if start_node in concept_key_list:\n",
    "            for end_node in match_relation_dict[start_node]:\n",
    "                if end_node in concept_key_list:\n",
    "                    match_relation_out.append(\n",
    "                        match_relation_dict[start_node][end_node])\n",
    "\n",
    "    return match_relation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_MODEL_BERT = \"phobert_large\"\n",
    "NER_MODEL_BILSTM = \"BiLSTM\"\n",
    "NER_MODEL_BILSTM_CRF = \"BiLSTM+CRF\"\n",
    "\n",
    "INTENT_MODEL_ONE_VS_REST = \"onevsrest\"\n",
    "\n",
    "\n",
    "def extract_ner(text, model=NER_MODEL_BERT):\n",
    "    \"\"\"\n",
    "    Input Arguments:\n",
    "        - text : the sentence which will be extracted NER\n",
    "    \"\"\"\n",
    "    ner_service_url = os.getenv(\"NER_SERVICE_URL\",\n",
    "                                default=\"http://localhost:8001/api/v1/ner\")\n",
    "\n",
    "    data = {'model': model, 'text': text}\n",
    "\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "\n",
    "    r = requests.post(ner_service_url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_postprocess(entities_raw):\n",
    "    \"\"\"Postprocess for NER: \n",
    "    1. normalize values\n",
    "    2. only accept the related information with previous question\n",
    "\n",
    "    Args:\n",
    "        entities_raw (Dict): result of NER service\n",
    "\n",
    "    Returns:\n",
    "        Dict, Dict: raw and normalized entities\n",
    "    \"\"\"\n",
    "    entities_normed = dict()\n",
    "    entities_raw_out = dict()\n",
    "\n",
    "    for entity in entities_raw:\n",
    "        key = entity['label']\n",
    "        if key == 'O': continue\n",
    "\n",
    "        value_raw = entity['content']\n",
    "        if key not in entities_raw_out.keys():\n",
    "            entities_raw_out[key] = [value_raw]\n",
    "        else:\n",
    "            entities_raw_out[key].append(value_raw)\n",
    "\n",
    "        value_normed = normalize(value_raw, key)\n",
    "        if key not in entities_normed.keys():\n",
    "            entities_normed[key] = [value_normed]\n",
    "        else:\n",
    "            entities_normed[key].append(value_normed)\n",
    "\n",
    "    return entities_raw_out, entities_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    entities_raw = extract_ner(text)\n",
    "    _, entities = ner_postprocess(entities_raw)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Remove the label which has a condition from returned_label.\n",
    "#\n",
    "# Argument:\n",
    "#     matched_labels: The labels which were matched.\n",
    "#     returned_labels: The labels which were returned.\n",
    "#     attr: condition attribute.\n",
    "# Return:\n",
    "#     returned_labels.\n",
    "# #\n",
    "def recheck_returned_labels(matched_labels, returned_labels, attr):\n",
    "    for match_label in matched_labels:\n",
    "        if attr in match_label:\n",
    "            returned_labels.remove(match_label)\n",
    "\n",
    "    return returned_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_query(concepts_keys, evidences_keys, targets, evidences,\n",
    "              match_relation):\n",
    "    out = \"\"\"\n",
    "    MATCH {} \n",
    "    WHERE {}\n",
    "    RETURN {}\n",
    "    LIMIT 50\n",
    "        \"\"\"\n",
    "    conditions = []\n",
    "    matched_labels = []  # Format: (alias:Node_name)\n",
    "    condition_labels = []  # Format: alias.individual = 'value'\n",
    "    returned_labels = []  # Format: (alias.individual)\n",
    "\n",
    "    ##\n",
    "    # Define matched labels.\n",
    "    # #\n",
    "    if not concepts_keys:\n",
    "        matched_labels = ['n']\n",
    "    else:\n",
    "        for idx, target in enumerate(concepts_keys):\n",
    "            matched_labels.append('(' + target + ':' + target.title() + ')')\n",
    "    ##\n",
    "    # Define returned labels.\n",
    "    # #\n",
    "    returned_labels = matched_labels.copy()\n",
    "\n",
    "    ##\n",
    "    # Define condition labels.\n",
    "    # #\n",
    "    attrs = [constants.LABEL_REAL_ESTATE_TYPE, constants.LABEL_REAL_ESTATE_SUB_TYPE, \\\n",
    "            constants.LABEL_POSITION, constants.LABEL_DIRECTION, \\\n",
    "            constants.LABEL_FRONT_LENGTH, constants.LABEL_ROAD_WIDTH, \\\n",
    "            constants.LABEL_FLOOR, constants.LABEL_BED_ROOM, constants.LABEL_LIVING_ROOM, constants.LABEL_BATH_ROOM, \\\n",
    "            constants.LABEL_SURROUNDING, constants.LABEL_PROJECT_NAME, \\\n",
    "            constants.LABEL_LEGAL, constants.LABEL_TRANSACTION]\n",
    "\n",
    "    key2dbcol = {\n",
    "        'tang': constants.LABEL_FLOOR,\n",
    "        'ban cong': constants.LABEL_FLOOR_BAN_CONG,\n",
    "        'gac': constants.LABEL_FLOOR_GAC,\n",
    "        'ham': constants.LABEL_FLOOR_HAM,\n",
    "        'lung': constants.LABEL_FLOOR_LUNG,\n",
    "        'san thuong': constants.LABEL_FLOOR_SAN_THUONG,\n",
    "        'tret': constants.LABEL_FLOOR_TRET\n",
    "    }\n",
    "\n",
    "    for attr in attrs:\n",
    "        if attr in evidences:\n",
    "            if attr == constants.LABEL_FLOOR:\n",
    "                for val in evidences[attr]:\n",
    "                    target_k = key2dbcol[val['type']]\n",
    "                    target_v = val['value']\n",
    "\n",
    "                    returned_labels = recheck_returned_labels(\n",
    "                        matched_labels, returned_labels, target_k)\n",
    "\n",
    "                    conditions.append(f\"{target_k}.individual = '{target_v}'\")\n",
    "            else:\n",
    "                returned_labels = recheck_returned_labels(\n",
    "                    matched_labels, returned_labels, attr)\n",
    "\n",
    "                if attr == constants.LABEL_REAL_ESTATE_TYPE or attr == constants.LABEL_REAL_ESTATE_SUB_TYPE:\n",
    "                    conditions.append(\n",
    "                        f\"{attr}.individual IN {evidences[attr]}\")\n",
    "                else:\n",
    "                    conditions.append(\n",
    "                        f\"{attr}.individual = '{evidences[attr][0]}'\")\n",
    "\n",
    "    ##\n",
    "    # Condition for city, district, ward, street.\n",
    "    # #\n",
    "    loc_attrs = [\n",
    "        constants.LABEL_DISTRICT, constants.LABEL_CITY, constants.LABEL_WARD,\n",
    "        constants.LABEL_STREET\n",
    "    ]\n",
    "\n",
    "    for attr in loc_attrs:\n",
    "        if attr in evidences:\n",
    "            returned_labels = recheck_returned_labels(matched_labels,\n",
    "                                                      returned_labels, attr)\n",
    "\n",
    "            conditions.append(f\"{attr}.individual = '{evidences[attr][0]}'\")\n",
    "\n",
    "    ##\n",
    "    # Condition for price.\n",
    "    # #\n",
    "    PRICE_OFFSET_CONST = 0.1\n",
    "\n",
    "    if constants.LABEL_PRICE in evidences:\n",
    "        for ele in evidences[constants.LABEL_PRICE][:1]:\n",
    "            low, high = ele\n",
    "\n",
    "            if high is None:\n",
    "                high = low + low * PRICE_OFFSET_CONST\n",
    "                low = low - low * PRICE_OFFSET_CONST\n",
    "\n",
    "            returned_labels = recheck_returned_labels(matched_labels,\n",
    "                                                      returned_labels,\n",
    "                                                      constants.LABEL_PRICE)\n",
    "\n",
    "            conditions.append(\n",
    "                f\"'{low}' <= {constants.LABEL_PRICE}.individual <= '{high}'\")\n",
    "\n",
    "    ##\n",
    "    # Condition for area.\n",
    "    # #\n",
    "    AREA_OFFSET_CONST = 0.1\n",
    "\n",
    "    if constants.LABEL_AREA in evidences:\n",
    "        for ele in evidences[constants.LABEL_AREA][:1]:\n",
    "            low, high = ele\n",
    "\n",
    "            if high is None:\n",
    "                high = low + low * AREA_OFFSET_CONST\n",
    "                low = low - low * AREA_OFFSET_CONST\n",
    "\n",
    "            returned_labels = recheck_returned_labels(matched_labels,\n",
    "                                                      returned_labels,\n",
    "                                                      constants.LABEL_AREA)\n",
    "\n",
    "            conditions.append(\n",
    "                f\"'{low}' <= {constants.LABEL_AREA}.individual <= '{high}'\")\n",
    "\n",
    "    ##\n",
    "    # Condition for usage.\n",
    "    # #\n",
    "    if constants.LABEL_USAGE in evidences:\n",
    "        returned_labels = recheck_returned_labels(matched_labels,\n",
    "                                                  returned_labels,\n",
    "                                                  constants.LABEL_USAGE)\n",
    "\n",
    "        conditions.append(\"({})\".format(\" OR \".join([\n",
    "            f\"{constants.LABEL_USAGE}.individual LIKE '%, {x},%' + 'OR {constants.LABEL_USAGE}.individual LIKE '{x}, %' OR {constants.LABEL_USAGE}.individual LIKE '%, {x}'\"\n",
    "            for x in evidences[constants.LABEL_USAGE]\n",
    "        ])))\n",
    "\n",
    "    ##\n",
    "    # Adjust returned labels\n",
    "    # #\n",
    "    adjusted_return_labels = []\n",
    "\n",
    "    for return_label in returned_labels:\n",
    "        return_label = f\"{return_label.split('(')[1].split(':')[0]} as {(return_label.split(':')[1].split(')')[0]).title()}\"\n",
    "\n",
    "        adjusted_return_labels.append(return_label)\n",
    "\n",
    "    return out.format(\n",
    "        ', '.join(match_relation),\n",
    "        ' \\nAND '.join([f\"{x}\" for x in conditions]),\n",
    "        ', '.join(adjusted_return_labels),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_query_ontology(text):\n",
    "    table = prettytable.PrettyTable([\"Step\", \"Result\"])\n",
    "    table.add_row([\"Input\", text])\n",
    "\n",
    "    concepts = get_concepts(text)\n",
    "\n",
    "    match_relation = get_match_relation(concepts.keys())\n",
    "\n",
    "    evidences = get_entities(text)\n",
    "\n",
    "    table.add_rows([[\"Match alias\", concepts], [\"Find individuals\",\n",
    "                                                evidences]])\n",
    "\n",
    "    targets = list(set(concepts.keys()).difference(set(evidences.keys())))\n",
    "    table.add_row([\"Target concepts\", targets])\n",
    "\n",
    "    query = gen_query(concepts.keys(), evidences.keys(), targets, evidences,\n",
    "                      match_relation)\n",
    "    table.add_row([\"Query\", query])\n",
    "\n",
    "    print(table)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|       Step       |                                                                           Result                                                                          |\n",
      "+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|      Input       |                                                 mình đang có 2 tỷ, nên mua nhà hoặc căn hộ ở quận nào nhỉ                                                 |\n",
      "|   Match alias    |                                  {'real_estate_type': 'căn hộ', 'transaction': 'mua', 'price': 'tỷ', 'district': 'quận'}                                  |\n",
      "| Find individuals |                              {'price': [(2000000000.0, None)], 'transaction': ['mua'], 'real_estate_type': ['nha', 'can ho']}                             |\n",
      "| Target concepts  |                                                                        ['district']                                                                       |\n",
      "|      Query       |                                                                                                                                                           |\n",
      "|                  |     MATCH (real_estate_type:House)-->(transaction:Transaction), (real_estate_type:House)-->(price:Price), (real_estate_type:House)-->(district:District)  |\n",
      "|                  |                                                    WHERE real_estate_type.individual IN ['nha', 'can ho']                                                 |\n",
      "|                  |                                                            AND transaction.individual = 'mua'                                                             |\n",
      "|                  |                                                  AND '1800000000.0' <= price.individual <= '2200000000.0'                                                 |\n",
      "|                  |                                                                  RETURN district as District                                                              |\n",
      "|                  |                                                                            LIMIT 50                                                                       |\n",
      "|                  |                                                                                                                                                           |\n",
      "+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# text = \"nhà ở quận 1 thường có giá khoảng bao nhiêu\"\n",
    "# text = \"nhà hoặc căn hộ giá khoảng 2 tỷ thì mua ở quận nào\"\n",
    "text = \"mình đang có 2 tỷ, nên mua nhà hoặc căn hộ ở quận nào nhỉ\"\n",
    "\n",
    "cqlNodeQuery = gen_query_ontology(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect neo4j DB.\n",
    "driver = GraphDatabase.driver('bolt://localhost:7687',\n",
    "                              auth=('neo4j', 'password'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    with driver.session(database=\"htdb\") as session:\n",
    "        results = session.run(query)\n",
    "\n",
    "        table_results = prettytable.PrettyTable(results.keys())\n",
    "        for r in results:\n",
    "            table_results.add_row(r.values())\n",
    "\n",
    "        return table_results\n",
    "        # return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<neo4j._sync.work.result.Result object at 0x0000015C3718AC48>\n"
     ]
    }
   ],
   "source": [
    "result_data = run_query(cqlNodeQuery)\n",
    "\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
