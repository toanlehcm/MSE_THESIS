{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import prettytable\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "from data_normalizer import normalize\n",
    "import constants\n",
    "from gen_query import handle_gen_query\n",
    "import util\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_MODEL_BERT = \"phobert_large\"\n",
    "NER_MODEL_BILSTM = \"BiLSTM\"\n",
    "NER_MODEL_BILSTM_CRF = \"BiLSTM+CRF\"\n",
    "\n",
    "INTENT_MODEL_ONE_VS_REST = \"onevsrest\"\n",
    "\n",
    "\n",
    "def extract_ner(text, model=NER_MODEL_BERT):\n",
    "    \"\"\"\n",
    "    Input Arguments:\n",
    "        - text : the sentence which will be extracted NER\n",
    "    \"\"\"\n",
    "    ner_service_url = os.getenv(\"NER_SERVICE_URL\",\n",
    "                                default=\"http://localhost:8001/api/v1/ner\")\n",
    "\n",
    "    data = {'model': model, 'text': text}\n",
    "\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "\n",
    "    r = requests.post(ner_service_url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_postprocess(entities_raw):\n",
    "    \"\"\"Postprocess for NER: \n",
    "    1. normalize values\n",
    "    2. only accept the related information with previous question\n",
    "\n",
    "    Args:\n",
    "        entities_raw (Dict): result of NER service\n",
    "\n",
    "    Returns:\n",
    "        Dict, Dict: raw and normalized entities\n",
    "    \"\"\"\n",
    "    entities_normed = dict()\n",
    "    entities_raw_out = dict()\n",
    "\n",
    "    for entity in entities_raw:\n",
    "        key = entity['label']\n",
    "        if key == 'O': continue\n",
    "\n",
    "        value_raw = entity['content']\n",
    "        if key not in entities_raw_out.keys():\n",
    "            entities_raw_out[key] = [value_raw]\n",
    "        else:\n",
    "            entities_raw_out[key].append(value_raw)\n",
    "\n",
    "        value_normed = normalize(value_raw, key)\n",
    "        if key not in entities_normed.keys():\n",
    "            entities_normed[key] = [value_normed]\n",
    "        else:\n",
    "            entities_normed[key].append(value_normed)\n",
    "\n",
    "    return entities_raw_out, entities_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    entities_raw = extract_ner(text)\n",
    "    _, entities = ner_postprocess(entities_raw)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_query_ontology(text):\n",
    "    table = prettytable.PrettyTable([\"Step\", \"Result\"])\n",
    "    table.max_width = 80\n",
    "    table.add_row([\"Input\", text])\n",
    "\n",
    "    concepts = util.get_concepts(text)\n",
    "\n",
    "    match_relation = util.get_match_relation(concepts.keys())\n",
    "\n",
    "    evidences = get_entities(text)\n",
    "\n",
    "    table.add_rows([[\"Match alias\", concepts], [\"Find individuals\",\n",
    "                                                evidences]])\n",
    "\n",
    "    targets = list(set(concepts.keys()).difference(set(evidences.keys())))\n",
    "    table.add_row([\"Target concepts\", targets])\n",
    "\n",
    "    query = handle_gen_query(concepts.keys(), evidences, match_relation)\n",
    "    table.add_row([\"Query\", query])\n",
    "\n",
    "    print(table)\n",
    "    # print(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------------------------------------------------+\n",
      "|       Step       |                                      Result                                      |\n",
      "+------------------+----------------------------------------------------------------------------------+\n",
      "|      Input       |                nhà hoặc căn hộ giá khoảng 2 tỷ thì mua ở quận nào                |\n",
      "|   Match alias    | {'real_estate_type': 'căn hộ', 'transaction': 'mua', 'price': 'giá', 'district': |\n",
      "|                  |                                  'ở quận nào'}                                   |\n",
      "| Find individuals |     {'real_estate_type': ['nha', 'can ho'], 'price': [(2000000000.0, None)],     |\n",
      "|                  |                             'transaction': ['mua']}                              |\n",
      "| Target concepts  |                                   ['district']                                   |\n",
      "|      Query       |                                                                                  |\n",
      "|                  |             MATCH (real_estate_type:House)-->(transaction:Transaction),          |\n",
      "|                  |                    (real_estate_type:House)-->(price:Price),                     |\n",
      "|                  |                  (real_estate_type:House)-->(district:District)                  |\n",
      "|                  |               WHERE real_estate_type.individual IN ['nha', 'can ho']             |\n",
      "|                  |                       AND transaction.individual = 'mua'                         |\n",
      "|                  |             AND '1800000000.0' <= price.individual <= '2200000000.0'             |\n",
      "|                  |               RETURN collect(distinct district.individual) AS District           |\n",
      "|                  |                                       LIMIT 50                                   |\n",
      "|                  |                                                                                  |\n",
      "+------------------+----------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "text = \"nhà hoặc căn hộ giá khoảng 2 tỷ thì mua ở quận nào\"\n",
    "\n",
    "cqlNodeQuery = gen_query_ontology(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect neo4j DB.\n",
    "driver = GraphDatabase.driver('bolt://localhost:7687',\n",
    "                              auth=('neo4j', 'password'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    with driver.session(database=\"htdb\") as session:\n",
    "        results = session.run(query)\n",
    "\n",
    "        table_results = prettytable.PrettyTable(results.keys())\n",
    "        table_results.max_width = 60\n",
    "        for r in results:\n",
    "            table_results.add_row(r.values())\n",
    "\n",
    "        return table_results\n",
    "        # return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "|                      District                      |\n",
      "+----------------------------------------------------+\n",
      "| ['hoang mai', '5 tu liem', 'long bien', 'kien an'] |\n",
      "+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "result_data = run_query(cqlNodeQuery)\n",
    "\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/question_dict.json', 'r', encoding=\"utf-8\") as fp:\n",
    "    question_dict = json.load(fp)\n",
    "    fp.close()\n",
    "\n",
    "REAL_ESTATE_TYPE = question_dict[\"real_estate_type\"]\n",
    "PRICE = question_dict[\"price\"]\n",
    "AREA = question_dict[\"area\"]\n",
    "DISTRICT = question_dict[\"district\"]\n",
    "BED_ROOM = question_dict[\"bed_room\"]\n",
    "FLOOR = question_dict[\"floor\"]\n",
    "LEGAL = question_dict[\"legal\"]\n",
    "POSITION = question_dict[\"position\"]\n",
    "LOCATION = question_dict[\"location\"]\n",
    "POTENTIAL = question_dict[\"potential\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
