{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from data_normalizer import normalize\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(text):\n",
    "    with open('data/intent_alias_data.json', encoding=\"utf8\") as f:\n",
    "        dictionary = json.load(f)\n",
    "    \n",
    "    out = {}\n",
    "    for concept in dictionary:\n",
    "        for alias in sorted(dictionary[concept], key=len, reverse=1):\n",
    "            if alias in text:\n",
    "                out[concept]=alias\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_MODEL_BERT = \"phobert_large\"\n",
    "NER_MODEL_BILSTM = \"BiLSTM\"\n",
    "NER_MODEL_BILSTM_CRF = \"BiLSTM+CRF\"\n",
    "\n",
    "INTENT_MODEL_ONE_VS_REST =\"onevsrest\"\n",
    "\n",
    "def extract_ner(text, model=NER_MODEL_BERT):\n",
    "    \"\"\"\n",
    "    Input Arguments:\n",
    "        - text : the sentence which will be extracted NER\n",
    "    \"\"\"\n",
    "    ner_service_url = os.getenv(\"NER_SERVICE_URL\", default=\"http://localhost:8001/api/v1/ner\")\n",
    "    data = {'model': model, 'text': text}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(ner_service_url, data=json.dumps(data), headers=headers)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_postprocess(entities_raw):\n",
    "    \"\"\"Postprocess for NER: \n",
    "    1. normalize values\n",
    "    2. only accept the related information with previous question\n",
    "\n",
    "    Args:\n",
    "        entities_raw (Dict): result of NER service\n",
    "\n",
    "    Returns:\n",
    "        Dict, Dict: raw and normalized entities\n",
    "    \"\"\"\n",
    "    entities_normed = dict()\n",
    "    entities_raw_out = dict()\n",
    "    for entity in entities_raw:\n",
    "        key = (entity['label']).title()\n",
    "        if key == 'O': continue\n",
    "        value_raw = entity['content']\n",
    "        if key not in entities_raw_out.keys():\n",
    "            entities_raw_out[key] = [value_raw]\n",
    "        else:\n",
    "            entities_raw_out[key].append(value_raw)\n",
    "        \n",
    "        value_normed = normalize(value_raw, key)\n",
    "        if key not in entities_normed.keys():\n",
    "            entities_normed[key] = [value_normed]\n",
    "        else:\n",
    "            entities_normed[key].append(value_normed)\n",
    "    \n",
    "    return entities_raw_out, entities_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    entities_raw = extract_ner(text)\n",
    "    _, entities = ner_postprocess(entities_raw)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "def gen_query(concepts_keys, evidences_keys, targets, evidences):\n",
    "    out = \"\"\"\n",
    "    MATCH {} \n",
    "    WHERE {}\n",
    "    RETURN {}\n",
    "    LIMIT 100\n",
    "        \"\"\"\n",
    "    conditions = []\n",
    "    matched_labels = []\n",
    "    idx_target_labels = []\n",
    "    condition_labels = []\n",
    "    \n",
    "    # Define matched labels.\n",
    "    if not concepts_keys:\n",
    "        matched_labels = ['n']\n",
    "    else:\n",
    "        for idx, target in enumerate(concepts_keys):\n",
    "            idx_target_labels.append('n' +str(idx))\n",
    "            matched_labels.append('(n' +str(idx) + ':' + target + ')')\n",
    "\n",
    "    # Define condition labels.\n",
    "    attrs = [constants.LABEL_REAL_ESTATE_TYPE, constants.LABEL_REAL_ESTATE_SUB_TYPE, \\\n",
    "            constants.LABEL_POSITION, constants.LABEL_DIRECTION, \\\n",
    "            constants.LABEL_FRONT_LENGTH, constants.LABEL_ROAD_WIDTH, \\\n",
    "            constants.LABEL_FLOOR, constants.LABEL_BED_ROOM, constants.LABEL_LIVING_ROOM, constants.LABEL_BATH_ROOM, \\\n",
    "            constants.LABEL_SURROUNDING, constants.LABEL_PROJECT_NAME, \\\n",
    "            constants.LABEL_LEGAL, constants.LABEL_TRANSACTION]\n",
    "    key2dbcol = {\n",
    "                'tang': constants.LABEL_FLOOR,\n",
    "                'ban cong': constants.LABEL_FLOOR_BAN_CONG,\n",
    "                'gac': constants.LABEL_FLOOR_GAC,\n",
    "                'ham': constants.LABEL_FLOOR_HAM,\n",
    "                'lung': constants.LABEL_FLOOR_LUNG,\n",
    "                'san thuong': constants.LABEL_FLOOR_SAN_THUONG,\n",
    "                'tret': constants.LABEL_FLOOR_TRET\n",
    "            }\n",
    "\n",
    "    for attr in attrs:\n",
    "        if attr in evidences:\n",
    "            if attr == constants.LABEL_FLOOR:\n",
    "                for val in evidences[attr]:\n",
    "                    target_k = key2dbcol[val['type']]\n",
    "                    target_v = val['value']\n",
    "                    conditions.append(f\"{target_k} = '{target_v}'\")\n",
    "            else:\n",
    "                conditions.append(f\"{attr}.individual = '{evidences[attr][0]}'\")\n",
    "    \n",
    "    loc_attrs = [constants.LABEL_DISTRICT, constants.LABEL_CITY, constants.LABEL_WARD, constants.LABEL_STREET]\n",
    "    for attr in loc_attrs:\n",
    "        attr = attr.title()\n",
    "        if attr in evidences:\n",
    "            for match_label in matched_labels:\n",
    "                if attr in match_label:\n",
    "                    idx_condition_node = match_label.split('(')[1].split(':')[0]\n",
    "                    idx_target_labels.remove(idx_condition_node)\n",
    "            \n",
    "            conditions.append(f\"{idx_condition_node}.individual = '{evidences[attr][0]}'\")\n",
    "    \n",
    "    PRICE_OFFSET_CONST = 0.1\n",
    "    if constants.LABEL_PRICE in evidences:\n",
    "        for ele in evidences[constants.LABEL_PRICE][:1]:\n",
    "            low, high = ele\n",
    "            if high is None:\n",
    "                high = low + low*PRICE_OFFSET_CONST\n",
    "                low = low - low*PRICE_OFFSET_CONST\n",
    "            \n",
    "            conditions.append(f\"{constants.LABEL_PRICE} BETWEEN {low} AND {high}\")\n",
    "    \n",
    "    AREA_OFFSET_CONST = 0.1\n",
    "    if constants.LABEL_AREA in evidences:\n",
    "        for ele in evidences[constants.LABEL_AREA][:1]:\n",
    "            low, high = ele\n",
    "            if high is None:\n",
    "                high = low + low*AREA_OFFSET_CONST\n",
    "                low = low - low*AREA_OFFSET_CONST\n",
    "            \n",
    "            conditions.append(f\"{constants.LABEL_AREA} BETWEEN {low} AND {high}\")\n",
    "    \n",
    "    if constants.LABEL_USAGE in evidences:\n",
    "        conditions.append(\"({})\".format(\" OR \".join([f\"{constants.LABEL_USAGE} LIKE '%, {x},%' OR {constants.LABEL_USAGE} LIKE '{x}, %' OR {constants.LABEL_USAGE} LIKE '%, {x}'\" for x in evidences[constants.LABEL_USAGE]])))\n",
    "\n",
    "    return out.format(\n",
    "        ', '.join(matched_labels),\n",
    "        ' AND '.join([f\"{x}\" for x in conditions]),\n",
    "        ', '.join(idx_target_labels),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "\n",
    "def gen_query_ontology(text):\n",
    "    table = prettytable.PrettyTable([\"Step\", \"Result\"])\n",
    "    table.add_row([\"Input\", text])\n",
    "    \n",
    "    concepts = get_concepts(text)\n",
    "    evidences = get_entities(text)\n",
    "    \n",
    "    table.add_rows([\n",
    "        [\"Match alias\", concepts],\n",
    "        [\"Find individuals\", evidences]\n",
    "    ])\n",
    "    \n",
    "    targets = list(set(concepts.keys()).difference(set(evidences.keys())))\n",
    "    table.add_row([\"Target concepts\", targets])\n",
    "\n",
    "    query = gen_query(concepts.keys(), evidences.keys(), targets, evidences)\n",
    "    table.add_row([\"Query\", query])\n",
    "    \n",
    "    print(table)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------------------------------------------+\n",
      "|       Step       |                                 Result                                |\n",
      "+------------------+-----------------------------------------------------------------------+\n",
      "|      Input       |              nhà ở quận 8 thường có giá khoảng bao nhiêu              |\n",
      "|   Match alias    | {'Price': 'giá khoảng bao nhiêu', 'District': 'quận', 'House': 'nhà'} |\n",
      "| Find individuals |                          {'District': ['8']}                          |\n",
      "| Target concepts  |                           ['House', 'Price']                          |\n",
      "|      Query       |                                                                       |\n",
      "|                  |                MATCH (n0:Price), (n1:District), (n2:House)            |\n",
      "|                  |                         WHERE n1.individual = '8'                     |\n",
      "|                  |                               RETURN n0, n2                           |\n",
      "|                  |                                 LIMIT 100                             |\n",
      "|                  |                                                                       |\n",
      "+------------------+-----------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "text = \"nhà ở quận 8 thường có giá khoảng bao nhiêu\"\n",
    "\n",
    "cqlNodeQuery = gen_query_ontology(text)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect neo4j desktop.\n",
    "driver = GraphDatabase.driver('bolt://localhost:7687', auth=('neo4j', 'password'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    with driver.session(database=\"htdb\") as session:\n",
    "        result = session.run(query)\n",
    "\n",
    "        # return result\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         n0                       n2\n",
      "0   (individual, alias, ID)  (individual, alias, ID)\n",
      "1   (individual, alias, ID)  (individual, alias, ID)\n",
      "2   (individual, alias, ID)  (individual, alias, ID)\n",
      "3   (individual, alias, ID)  (individual, alias, ID)\n",
      "4   (individual, alias, ID)  (individual, alias, ID)\n",
      "..                      ...                      ...\n",
      "95  (individual, alias, ID)  (individual, alias, ID)\n",
      "96  (individual, alias, ID)  (individual, alias, ID)\n",
      "97  (individual, alias, ID)  (individual, alias, ID)\n",
      "98  (individual, alias, ID)  (individual, alias, ID)\n",
      "99  (individual, alias, ID)  (individual, alias, ID)\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result_data = run_query(cqlNodeQuery)\n",
    "\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
