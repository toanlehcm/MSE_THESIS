{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# nlp = spacy.load('vi_core_news_lg')\n",
    "# nlp = spacy.load('vi_spacy_model')\n",
    "# nlp = spacy.load(\"xx_sent_ud_sm\")\n",
    "nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hôm nay trời nắng to\n"
     ]
    }
   ],
   "source": [
    "# doc = nlp(\"Hôm nay trời nắng to\")\n",
    "# displacy.serve(doc, style=\"dep\")\n",
    "# \n",
    "doc = nlp(\"Hôm nay trời nắng to\")\n",
    "# displacy.serve(doc, style=\"ent\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cộng     Xxxx True False\n",
      "đồng     xxxx True False\n",
      "xử     xx True False\n",
      "lý     xx True False\n",
      "ngôn     xxxx True False\n",
      "ngữ     xxx True False\n",
      "tự     xx True False\n",
      "nhiên     xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Cộng đồng xử lý ngôn ngữ tự nhiên')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import wikipedia sentences\n",
    "# candidate_sentences = pd.read_csv(\"wiki_sentences_v2.csv\")\n",
    "candidate_sentences = pd.read_csv(\"sentences_vn.csv\")\n",
    "candidate_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154             vào tháng 1 năm 2017, johns và berg đã báo cáo cho emmerich.\n",
       "475         dàn diễn viên xuất hiện thông qua hình ba chiều ma của hạt tiêu.\n",
       "426                         thiết kế sản xuất đã được xử lý bởi t. muthuraj.\n",
       "9                                         chúng tôi chỉ cố gắng làm bộ phim.\n",
       "396    giá trị nghệ thuật của âm nhạc điện ảnh thường xuyên được tranh luận.\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_sentences['sentence'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bối rối và thất vọng, connie quyết định rời đi một mình.\n",
      "bối ... \n",
      "rối ... \n",
      "và ... \n",
      "thất ... \n",
      "vọng ... \n",
      ", ... \n",
      "connie ... \n",
      "quyết ... \n",
      "định ... \n",
      "rời ... \n",
      "đi ... \n",
      "một ... \n",
      "mình ... \n",
      ". ... \n"
     ]
    }
   ],
   "source": [
    "# doc = nlp(\"the drawdown process is governed by astm standard d823\")\n",
    "doc = nlp(\"bối rối và thất vọng, connie quyết định rời đi một mình.\")\n",
    "print(doc)\n",
    "\n",
    "for tok in doc:\n",
    "  print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "    ## chunk 1\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "\n",
    "    prv_tok_dep = \"\"  # dependency tag of previous token in the sentence\n",
    "    prv_tok_text = \"\"  # previous token in the sentence\n",
    "\n",
    "    prefix = \"\"\n",
    "    modifier = \"\"\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    for tok in nlp(sent):\n",
    "        ## chunk 2\n",
    "        # nếu token là một dấu chấm câu thì chuyển sang token tiếp theo\n",
    "        if tok.dep_ != \"punct\":\n",
    "            # check: token có phải là một từ ghép hay không\n",
    "            if tok.dep_ == \"compound\":\n",
    "                prefix = tok.text\n",
    "                # nếu từ trước đó cũng là một 'từ ghép' thì hãy thêm từ hiện tại vào nó\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    prefix = prv_tok_text + \" \" + tok.text\n",
    "\n",
    "            # check: token là một bổ ngữ hay không\n",
    "            if tok.dep_.endswith(\"mod\") == True:\n",
    "                modifier = tok.text\n",
    "                # nếu từ trước đó cũng là một 'từ ghép' thì hãy thêm từ hiện tại vào nó\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    modifier = prv_tok_text + \" \" + tok.text\n",
    "\n",
    "            ## chunk 3\n",
    "            if tok.dep_.find(\"subj\") == True:\n",
    "                ent1 = modifier + \" \" + prefix + \" \" + tok.text\n",
    "                prefix = \"\"\n",
    "                modifier = \"\"\n",
    "                prv_tok_dep = \"\"\n",
    "                prv_tok_text = \"\"\n",
    "\n",
    "            ## chunk 4\n",
    "            if tok.dep_.find(\"obj\") == True:\n",
    "                ent2 = modifier + \" \" + prefix + \" \" + tok.text\n",
    "\n",
    "            ## chunk 5\n",
    "            # update variables\n",
    "            prv_tok_dep = tok.dep_\n",
    "            prv_tok_text = tok.text\n",
    "    #############################################################\n",
    "\n",
    "    return [ent1.strip(), ent2.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(\"bối rối và thất vọng, connie quyết định rời đi một mình.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:01<00:00, 334.60it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_pairs = []\n",
    "\n",
    "for i in tqdm(candidate_sentences[\"sentence\"]):\n",
    "    entity_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', ''],\n",
       " ['', '']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_pairs[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_relation(sent):\n",
    "\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Matcher class object\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    print(\"matcher: \", matcher)\n",
    "    print(\"nlp.vocab: \", nlp.vocab)\n",
    "\n",
    "    #define the pattern\n",
    "    pattern = [[{\n",
    "        'DEP': 'ROOT'\n",
    "    }, {\n",
    "        'DEP': 'prep',\n",
    "        'OP': \"?\"\n",
    "    }, {\n",
    "        'DEP': 'agent',\n",
    "        'OP': \"?\"\n",
    "    }, {\n",
    "        'POS': 'ADJ',\n",
    "        'OP': \"?\"\n",
    "    }]]\n",
    "\n",
    "    matcher.add(\"matching_1\", patterns = pattern)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    k = len(matches) - 1  \n",
    "    # print(\"matches: \", matches)\n",
    "    # print(\"type(matches): \", type(matches))\n",
    "    # print(\"len(matches): \", len(matches))\n",
    "    # print(\"k: \", k)\n",
    "    \n",
    "    tmpSpan = \"\"\n",
    "    if len(matches) >= 1:\n",
    "      span = doc[matches[k][1]:matches[k][2]]\n",
    "      tmpSpan = span.text\n",
    "      # print(\"span: \", span.text)\n",
    "      # print(\"type(span): \", type(span.text))\n",
    "      # print(\"---\")\n",
    "\n",
    "    # return (span.text)\n",
    "    return(tmpSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matcher:  <spacy.matcher.matcher.Matcher object at 0x7fed1100bb40>\n",
      "nlp.vocab:  <spacy.vocab.Vocab object at 0x7fed0fd190d0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E155] The pipeline needs to include a morphologizer or tagger+attribute_ruler in order to use Matcher or PhraseMatcher with the attribute POS. Try using `nlp()` instead of `nlp.make_doc()` or `list(nlp.pipe())` instead of `list(nlp.tokenizer.pipe())`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39m# get_relation(\"John completed the task\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000009?line=1'>2</a>\u001b[0m get_relation(\u001b[39m\"\u001b[39;49m\u001b[39mbối rối và thất vọng, connie quyết định rời đi một mình.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 11'\u001b[0m in \u001b[0;36mget_relation\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=10'>11</a>\u001b[0m pattern \u001b[39m=\u001b[39m [[{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mDEP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mROOT\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=12'>13</a>\u001b[0m }, {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=20'>21</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mOP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=21'>22</a>\u001b[0m }]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=23'>24</a>\u001b[0m matcher\u001b[39m.\u001b[39madd(\u001b[39m\"\u001b[39m\u001b[39mmatching_1\u001b[39m\u001b[39m\"\u001b[39m, patterns \u001b[39m=\u001b[39m pattern)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=25'>26</a>\u001b[0m matches \u001b[39m=\u001b[39m matcher(doc)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=26'>27</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(matches) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=27'>28</a>\u001b[0m \u001b[39m# print(\"matches: \", matches)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=28'>29</a>\u001b[0m \u001b[39m# print(\"type(matches): \", type(matches))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=29'>30</a>\u001b[0m \u001b[39m# print(\"len(matches): \", len(matches))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=30'>31</a>\u001b[0m \u001b[39m# print(\"k: \", k)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/spacy/matcher/matcher.pyx:248\u001b[0m, in \u001b[0;36mspacy.matcher.matcher.Matcher.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E155] The pipeline needs to include a morphologizer or tagger+attribute_ruler in order to use Matcher or PhraseMatcher with the attribute POS. Try using `nlp()` instead of `nlp.make_doc()` or `list(nlp.pipe())` instead of `list(nlp.tokenizer.pipe())`."
     ]
    }
   ],
   "source": [
    "# get_relation(\"John completed the task\")\n",
    "get_relation(\"bối rối và thất vọng, connie quyết định rời đi một mình.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/488 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matcher:  <spacy.matcher.matcher.Matcher object at 0x7fed0f7fd940>\n",
      "nlp.vocab:  <spacy.vocab.Vocab object at 0x7fed0fd190d0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E155] The pipeline needs to include a morphologizer or tagger+attribute_ruler in order to use Matcher or PhraseMatcher with the attribute POS. Try using `nlp()` instead of `nlp.make_doc()` or `list(nlp.pipe())` instead of `list(nlp.tokenizer.pipe())`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000010?line=0'>1</a>\u001b[0m relations \u001b[39m=\u001b[39m [get_relation(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(candidate_sentences[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 13'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000010?line=0'>1</a>\u001b[0m relations \u001b[39m=\u001b[39m [get_relation(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(candidate_sentences[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m])]\n",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 11'\u001b[0m in \u001b[0;36mget_relation\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=10'>11</a>\u001b[0m pattern \u001b[39m=\u001b[39m [[{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mDEP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mROOT\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=12'>13</a>\u001b[0m }, {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=20'>21</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mOP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=21'>22</a>\u001b[0m }]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=23'>24</a>\u001b[0m matcher\u001b[39m.\u001b[39madd(\u001b[39m\"\u001b[39m\u001b[39mmatching_1\u001b[39m\u001b[39m\"\u001b[39m, patterns \u001b[39m=\u001b[39m pattern)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=25'>26</a>\u001b[0m matches \u001b[39m=\u001b[39m matcher(doc)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=26'>27</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(matches) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=27'>28</a>\u001b[0m \u001b[39m# print(\"matches: \", matches)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=28'>29</a>\u001b[0m \u001b[39m# print(\"type(matches): \", type(matches))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=29'>30</a>\u001b[0m \u001b[39m# print(\"len(matches): \", len(matches))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000008?line=30'>31</a>\u001b[0m \u001b[39m# print(\"k: \", k)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/spacy/matcher/matcher.pyx:248\u001b[0m, in \u001b[0;36mspacy.matcher.matcher.Matcher.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E155] The pipeline needs to include a morphologizer or tagger+attribute_ruler in order to use Matcher or PhraseMatcher with the attribute POS. Try using `nlp()` instead of `nlp.make_doc()` or `list(nlp.pipe())` instead of `list(nlp.tokenizer.pipe())`."
     ]
    }
   ],
   "source": [
    "relations = [get_relation(i) for i in tqdm(candidate_sentences['sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "với        15\n",
       "tháng      15\n",
       "có         14\n",
       "nhạc       12\n",
       "ảnh        12\n",
       "được       10\n",
       "nhất        9\n",
       "hoan        8\n",
       "diễn        8\n",
       "tôi         7\n",
       "của         6\n",
       "đầu         6\n",
       "kiến        5\n",
       "hành        5\n",
       "những       5\n",
       "cầu         5\n",
       "cảm         5\n",
       "cùng        5\n",
       "thành       4\n",
       "tiên        4\n",
       "án          3\n",
       "nhau        3\n",
       "sung        3\n",
       "viên        3\n",
       "giám        3\n",
       "do          3\n",
       "địa         3\n",
       "ra          3\n",
       "thương      3\n",
       "kịch        3\n",
       "phương      3\n",
       "loạt        3\n",
       "làm         3\n",
       "nó          3\n",
       "thật        3\n",
       "cung        3\n",
       "giới        3\n",
       "thất        2\n",
       "theo        2\n",
       "chính       2\n",
       "aquaman     2\n",
       "giờ         2\n",
       "hậu         2\n",
       "lillis      2\n",
       "đại         2\n",
       "chương      2\n",
       "lại         2\n",
       "giao        2\n",
       "nhận        2\n",
       "cố          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(relations).value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subject\n",
    "source = [i[0] for i in entity_pairs]\n",
    "\n",
    "# extract object\n",
    "target = [i[1] for i in entity_pairs]\n",
    "\n",
    "# print('source', len(source))\n",
    "# print('target', len(target))\n",
    "# print('edge', len(relations))\n",
    "\n",
    "kg_df = pd.DataFrame({'source': source, 'target': target, 'edge': relations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed-graph from a dataframe\n",
    "G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n",
    "                          edge_attr=True, create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000021?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m12\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000021?line=2'>3</a>\u001b[0m pos \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mspring_layout(G)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000021?line=3'>4</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw(G, with_labels\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, node_color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mskyblue\u001b[39m\u001b[39m'\u001b[39m, edge_cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mBlues, pos \u001b[39m=\u001b[39m pos)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000021?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 8:4\u001b[0m, in \u001b[0;36margmap_spring_layout_5\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m splitext\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager\n\u001b[0;32m----> <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_random_state, create_py_random_state\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py:476\u001b[0m, in \u001b[0;36mspring_layout\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=473'>474</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(G) \u001b[39m<\u001b[39m \u001b[39m500\u001b[39m:  \u001b[39m# sparse solver for large graphs\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=474'>475</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=475'>476</a>\u001b[0m A \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mto_scipy_sparse_array(G, weight\u001b[39m=\u001b[39;49mweight, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=476'>477</a>\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m fixed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=477'>478</a>\u001b[0m     \u001b[39m# We must adjust k by domain size for layouts not near 1x1\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=478'>479</a>\u001b[0m     nnodes, _ \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py:907\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=903'>904</a>\u001b[0m     row, col, data \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=905'>906</a>\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39mis_directed():\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=906'>907</a>\u001b[0m     A \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcoo_array((data, (row, col)), shape\u001b[39m=\u001b[39m(nlen, nlen), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=907'>908</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=908'>909</a>\u001b[0m     \u001b[39m# symmetrize matrix\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=909'>910</a>\u001b[0m     d \u001b[39m=\u001b[39m data \u001b[39m+\u001b[39m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed-graph from a dataframe\n",
    "G = nx.from_pandas_edgelist(kg_df[kg_df['edge'] == \"composed by\"],\n",
    "                            \"source\",\n",
    "                            \"target\",\n",
    "                            edge_attr=True,\n",
    "                            create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 538 nodes and 488 edges\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m12\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=1'>2</a>\u001b[0m pos \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mspring_layout(G, k\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)  \u001b[39m# k regulates the distance between nodes\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=2'>3</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw(G,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=3'>4</a>\u001b[0m         with_labels\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=4'>5</a>\u001b[0m         node_color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mskyblue\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=5'>6</a>\u001b[0m         node_size\u001b[39m=\u001b[39m\u001b[39m1500\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=6'>7</a>\u001b[0m         edge_cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mBlues,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=7'>8</a>\u001b[0m         pos\u001b[39m=\u001b[39mpos)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/toanlethanh/Documents/0_MSE/3_6_THESIS_SEM501/ToanLe/thesisSource/ontologyTrain.ipynb#ch0000007?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 8:4\u001b[0m, in \u001b[0;36margmap_spring_layout_5\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m splitext\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager\n\u001b[0;32m----> <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[1;32m      <a href='file:///%3Cclass%20%27networkx.utils.decorators.argmap%27%3E%20compilation%208?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_random_state, create_py_random_state\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py:476\u001b[0m, in \u001b[0;36mspring_layout\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=473'>474</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(G) \u001b[39m<\u001b[39m \u001b[39m500\u001b[39m:  \u001b[39m# sparse solver for large graphs\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=474'>475</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=475'>476</a>\u001b[0m A \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mto_scipy_sparse_array(G, weight\u001b[39m=\u001b[39;49mweight, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=476'>477</a>\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m fixed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=477'>478</a>\u001b[0m     \u001b[39m# We must adjust k by domain size for layouts not near 1x1\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/drawing/layout.py?line=478'>479</a>\u001b[0m     nnodes, _ \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py:907\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=903'>904</a>\u001b[0m     row, col, data \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=905'>906</a>\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39mis_directed():\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=906'>907</a>\u001b[0m     A \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcoo_array((data, (row, col)), shape\u001b[39m=\u001b[39m(nlen, nlen), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=907'>908</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=908'>909</a>\u001b[0m     \u001b[39m# symmetrize matrix\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/networkx/convert_matrix.py?line=909'>910</a>\u001b[0m     d \u001b[39m=\u001b[39m data \u001b[39m+\u001b[39m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G, k=0.5)  # k regulates the distance between nodes\n",
    "nx.draw(G,\n",
    "        with_labels=True,\n",
    "        node_color='skyblue',\n",
    "        node_size=1500,\n",
    "        edge_cmap=plt.cm.Blues,\n",
    "        pos=pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
